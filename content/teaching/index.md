---
title: Teaching
summary: Courses I have taught
date: "2021-07-23T00:00:00Z"

reading_time: false  # Show estimated reading time?
share: false  # Show social sharing links?
profile: false  # Show author profile?
comments: false  # Show comments?

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
image:
  placement: 1
  caption: ''
  focal_point: ""
  preview_only: false
  alt_text: 'headshot of Benjamin Xie'

# Optional header image (relative to `assets/media/` folder).
header:
  caption: ""
  image: ""
---

_In various capacities, I have supported teaching and learning in Stanford computer science courses, University of Washington informatics courses, and high school computer science classes while at MIT._

## Stanford Computer Science
From 2022-2024, I served as an [Embedded Ethics Fellow](https://web.archive.org/web/20230923145302/https://ethicsinsociety.stanford.edu/people/benjamin-xie). Within this role, I worked with faculty members and teaching assistants in the [CS department](https://www.cs.stanford.edu/) as well as philosophers in the [McCoy Family Center for Ethics](https://ethicsinsociety.stanford.edu/) to embed ethics into undergraduate courses. This role primarily involved curriculum development (lectures, assignments, exam questions, TA-led section content) and guest lecturing.

Within this role, I co-organized a [conference on _Teaching Responsible Computer Science_](https://hai.stanford.edu/news/teaching-responsible-computer-science) which occurred March 2023 and was attended by over 100 higher education educators and industry affiliates.

Here are the courses I embedded ethics into, with some notable contributions:

### Programming Methodologies (CS 106A) 
Wi ʼ23, Sp ʼ23, Fa ʼ23

### Programming Abstractions (CS 106B)
[Sp ʼ23](https://web.stanford.edu/class/archive/cs/cs106b/cs106b.1236/), Fa ʼ23, Wi ʼ24

### Operating Systems Principles (CS 111)
Wi ʼ23, Sp ʼ23, [Fa ʼ23](https://web.stanford.edu/class/archive/cs/cs111/cs111.1242/), Wi ʼ24

In this introductory operating systems class, I worked with William Grant Ray III, Xiyu Zhang, Liana Keesing, Swayam Parida, Prof. Nick Troccoli, and Prof. John Ousterhout to teach about the relationship between operating systems and trust [two page explainer](https://docs.google.com/document/d/1IhggFHVtmad4jcWp07SwVnKhcg2-tzeq/edit?usp=sharing&ouid=117609706951924954885&rtpof=true&sd=true). We ended up developing two 50 minute ethics lectures, two accompanying assignment questions, and questions for the midterm and final.

- [Assignment 2, Exercise 3](https://web.stanford.edu/class/archive/cs/cs111/cs111.1242/assign2/) on trust and OS long-term support.

- [Ethics Lecture 1](https://web.stanford.edu/class/archive/cs/cs111/cs111.1242/lectures/16/Lecture16.pdf)): Trust and OS. Motivated why trust was relevant to operating systems; framed trust as an unquestioning attitude; identified 3 ways trust manifests (assumption, inference, substitution), and used the Linux kernel as an example of how trust manifests for users, app developers, and systems programmers.

- [Assignment 4, Exercise 3](https://web.stanford.edu/class/archive/cs/cs111/cs111.1242/assign4/) asked students to apply this framework of trust to understand the impact of a race condition to a voice chat app (Google Duo)

- [Ethics Lecture 2](https://web.stanford.edu/class/archive/cs/cs111/cs111.1242/lectures/16/Lecture16.pdf): Trust & Context. Engaged students with thinking of contextual factors that affect how we consider and communicate trust. Four dimensions of context are drawn from Value Sensitive Design and include stakeholders, time, values, pervasiveness. Examples I use include Therac-25, continuity of OS for ended Pebble smart watches.

### Design & Analysis of Algorithms (CS 161)
Fa ʼ22

I developed a second ethics lecture on different framings of equity applied to hiring algorithms. This drew upon framings of equity by [Levinson, Geron, & Brighouse 2022](https://doi.org/10.1177/2332858422112134) and used [Geyik, Ambler, & Kenthapadi 2019](https://doi.org/10.1145/3292500.3330691)'s det-greedy algorithm as an example.


### Human-Centered Product Management (CS 177)
Fa ʼ22

### Natural Language Processing with Deep Learning (CS 224N)
Wi ʼ24

## University of Washington Information School
During my Ph.D. at the UW Information School, I served as a co-instructor of record, seminar leader, head teaching assistant, and teaching assistant across various courses relating to data programming, machine learning, and software design, as well as a seminar on critical demography.

### Introduction to Data Science (INFO 370)
[Fa ʼ17](https://web.archive.org/web/20210308202833/https://students.washington.edu/bxie/info370/) (34 students)

During my second year of my Ph.D., I **designed and co-instructed** a new undergraduate course for the first time. My co-instructor was a more senior Ph.D. student, Greg L. Nelson (now an assistant professor at University of Maine CS). This course took a more human-centered approach, framing data science as an interactive and iterative process of using computational tools to analyze data within organizational and social contexts to inform decisions.

The course materials were [shared by Women in Statistics and Data Science's Twitter](https://twitter.com/WomenInStat/status/1374432602128482315).


### Seminar on Identity, Demographic Data, and Computing Education (INFO 499)
Wi ʼ22 (8 students, remote)

I **led a seminar** with 8 undergraduate students on how we reduce identity down to demographic data and what the implications of this were to computing education. This seminar was part of Prof. Amy Ko's [Lablet](https://faculty.washington.edu/ajko/lablets) experiment to engage more undergraduates in computing education research.


### Advanced Methods in Data Science (INFO 371) 
Wi ʼ21 (60 students, remote)

I served as a **teaching assistant** for a 60 person course taught by Prof. [Jevin West](https://www.jevinwest.org/). This course taught applied machine learning and data science techniques. I gave a lecture on the fundamentals of gradient descent, as well as its applications by activists to thwart government surveillance. Within this lecture, I also facilitated a discussion on how different positionalities affect how stakeholders may wield the same tools differently.

### Technical Foundations of Informatics (INFO 201)
Fa ʼ19 (200 students)

I served as **head TA** for this introductory data programming course taught by Prof. [Dave Hendry](https://ischool.uw.edu/people/faculty/profile/dhendry). My role involved training undergraduate TAs in inclusive teaching and fair assessment practices. Drawing upon my training in educational statistics, I used psychometric techniques to identify biases in grading by TAs and mitigated these biases by the middle of the quarter.


### Cooperative Software Design, UW INFO 461
Sp ʼ17 (35 students)

I served as the **TA** for this course taught by Prof. [Amy Ko](https://faculty.washington.edu/ajko/). This course taught late-stage undergraduates to apply software engineering principles as they worked in large groups to design, develop, and iterate on web applications. I made minor contributions to a [book Prof. Ko wrote](https://faculty.washington.edu/ajko/books/cooperative-software-development/) about the topics in this course. 

### Introduction to Computer Science, Prospect Hill Academy. 
Fa ʼ14, Sp ʼ15

As part of my three course [education concentration](https://cmsw.mit.edu/education/comparative-media-studies/undergraduate/education-concentration/) at MIT, I spent multiple semesters serving as a **part-time TA** with two teaches at Prospect Hill Academy. I got to work with racially & socio-economically diverse high school students to build their capacity to express themselves with tools such as [PencilCode](https://pencilcode.net/).

I [blogged](https://yoursistheearth.wordpress.com/) about my experiences.
